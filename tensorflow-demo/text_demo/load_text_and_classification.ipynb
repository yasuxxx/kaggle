{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RNN文本分类\n",
    "# 主要的步骤就是\n",
    "# 1. 构造数据\n",
    "# 2. 搭建模型\n",
    "# 3. 设置损失和优化器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/mi/.keras/datasets'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "FILE_NAMES = ['cowper.txt','derby.txt','butler.txt']\n",
    "\n",
    "for name in FILE_NAMES:\n",
    "    text_dir = tf.keras.utils.get_file(name,origin=DIRECTORY_URL+name)\n",
    "\n",
    "parent_dir = os.path.dirname(text_dir)\n",
    "parent_dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n",
      "<MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n",
      "<MapDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "def labeler(example,index):\n",
    "    #tf.cast 执行数据类型转换\n",
    "    return example,tf.cast(index,tf.int64)\n",
    "\n",
    "label_data_sets = []\n",
    "for i,file_name in enumerate(FILE_NAMES):\n",
    "    # 从第i个文件中取出每行句子\n",
    "    lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir,file_name))\n",
    "    # 数据转换  (line=> (line,i)) 其中i表示line这行数据所属类别\n",
    "    # map函数和scala的map函数类似\n",
    "    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex,i))\n",
    "    # 行和标签组成的数据集\n",
    "    label_data_sets.append(labeled_dataset)\n",
    "for v in label_data_sets:\n",
    "    print(v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 16\n",
    "TAKE_SIZE = 5000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "all_labeled_data = label_data_sets[0]\n",
    "for labeled_dataset in label_data_sets[1:]:\n",
    "    # 将dataset拼起来\n",
    "    all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
    "\n",
    "# reshuffle为True的意思是 来个新的iter就重新shuffle一次\n",
    "all_labeled_data = all_labeled_data.shuffle(BUFFER_SIZE,reshuffle_each_iteration=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 10:12:30.367380: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-29 10:12:30.385774: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'About the pyre a chosen band of Greeks'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'His swift ambassadress to sacred Troy.'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'From topmost boughs of forest tree sends forth'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"She, in the midst, was weeping o'er the fate\">, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"No, not though Priam's royal self should sue\">, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for ex in all_labeled_data.take(5):print(ex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "\n",
    "# set来保证不重复\n",
    "vocabulary_set = set()\n",
    "for text_tensor,_ in all_labeled_data:\n",
    "    some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "    # 增量更新set用update\n",
    "    vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_text:b'About the pyre a chosen band of Greeks'\n",
      "example_encode:[6337, 404, 3185, 2771, 8569, 10160, 10474, 13576]\n"
     ]
    }
   ],
   "source": [
    "# 利用tf自带的库来构造编码器\n",
    "encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set)\n",
    "\n",
    "# 文本的原始数据\n",
    "example_txt = next(iter(all_labeled_data))[0].numpy()\n",
    "# 文本编码后的数据\n",
    "example_encode = encoder.encode(example_txt)\n",
    "\n",
    "# 单条数据的文本编码\n",
    "print(f'example_text:{example_txt}\\n'\n",
    "      f'example_encode:{example_encode}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(8,), dtype=int64, numpy=array([ 6337,   404,  3185,  2771,  8569, 10160, 10474, 13576])>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(6,), dtype=int64, numpy=array([15105,  3602, 17124,   477, 17085,  2575])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(8,), dtype=int64, numpy=array([ 5983,  2000,  2944, 10474, 10136, 14649,  3174,  6228])>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(10,), dtype=int64, numpy=\n",
      "array([ 4160,  1167,   404, 14013,  6928,  2218, 13912, 13263,   404,\n",
      "         178])>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(9,), dtype=int64, numpy=array([10184,  5578,  4506, 16840,  9879, 14560,  7904, 11699, 16533])>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# 抽象成编码函数\n",
    "def encode(text_tensor,label):\n",
    "    encode_text = encoder.encode(text_tensor.numpy())\n",
    "    return encode_text,label\n",
    "\n",
    "#\n",
    "def encode_map_fn(text,label):\n",
    "    # 将Python函数包装成tensorflow的算子\n",
    "    encode_text,label = tf.py_function(encode,\n",
    "                                       inp=[text,label], #输入\n",
    "\n",
    "                                       Tout=(tf.int64,tf.int64)) #输出格式\n",
    "    # None保证text具有动态形状\n",
    "    encode_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "\n",
    "    return encode_text,label\n",
    "\n",
    "# 将数据和标签拼起来\n",
    "all_encoded_data = all_labeled_data.map(encode_map_fn)\n",
    "for v in all_encoded_data.take(5):print(v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# skip函数跳过的数据用于做test,之后的用作训练集\n",
    "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(64)\n",
    "\n",
    "# 测试集的数据构造\n",
    "test_data = all_encoded_data.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(16,), dtype=int64, numpy=\n array([ 6337,   404,  3185,  2771,  8569, 10160, 10474, 13576,     0,\n            0,     0,     0,     0,     0,     0,     0])>,\n <tf.Tensor: shape=(), dtype=int64, numpy=1>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text,sample_labels = next(iter(test_data))\n",
    "sample_text[0],sample_labels[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "vocab_size += 1  # 用作特殊字符占位"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 64)          1099456   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,178,115\n",
      "Trainable params: 1,178,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构造模型\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size,64))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "for units in [64,64]:\n",
    "    model.add(tf.keras.layers.Dense(units,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          1099456   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,178,115\n",
      "Trainable params: 1,178,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', #梯度更新优化器\n",
    "              loss='sparse_categorical_crossentropy', # 损失函数\n",
    "              metrics = ['accuracy']) # 衡量方式\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/697 [==============================] - 46s 54ms/step - loss: 0.6616 - accuracy: 0.6593 - val_loss: 0.3824 - val_accuracy: 0.8312\n",
      "Epoch 2/3\n",
      "697/697 [==============================] - 44s 56ms/step - loss: 0.3097 - accuracy: 0.8649 - val_loss: 0.3418 - val_accuracy: 0.8444\n",
      "Epoch 3/3\n",
      "697/697 [==============================] - 48s 61ms/step - loss: 0.2237 - accuracy: 0.9068 - val_loss: 0.3552 - val_accuracy: 0.8450\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f99863d9d30>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练和验证\n",
    "model.fit(train_data,epochs=3,validation_data=test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "input = next(iter(test_data))[0]\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size,64))\n",
    "model.compile('rmsprop', 'mse')\n",
    "output = model.predict(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}